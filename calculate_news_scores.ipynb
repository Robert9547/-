{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 說明:\n",
    "# 本ipynb利用情緒詞字典幫新聞文章算出正負面的分數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "#import logging\n",
    "import pandas as pd\n",
    "import string\n",
    "import import_ipynb\n",
    "from collections import defaultdict\n",
    "from emotionalDictionaryExtractor import get_positive_emotional_tokens\n",
    "from emotionalDictionaryExtractor import get_negative_emotional_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#第一次使用jieba套件時要執行以下程式碼\n",
    "# jieba.set_dictionary('chinese_tokens_for_jieba\\dict.txt.big') #讓jieba使用繁體詞庫來斷詞\n",
    "# jieba.setLogLevel(logging.ERROR)  #jieba跑程式時不會出現一堆log輸出(如jieba Prefix dict has been built successfully)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全域變數\n",
    "good_word = get_positive_emotional_tokens() #所有正向情緒詞彙\n",
    "bad_word = get_negative_emotional_tokens()  #所有負向情緒詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#對新聞文章的內文進行中文斷詞\n",
    "def chineseWordTokenizer(newsText:str) -> list:\n",
    "    #讓jieba切token\n",
    "    tokens = jieba.lcut(newsText)\n",
    "    \n",
    "    #去除標點符號\n",
    "    chinesePunctuations = ['＂', '＃', '＄', '％', '＆', '＇', '（', '）', '＊', '＋', '，', '－', '／', '：', '；', '＜', '＝', '＞', '＠', '［', '＼', '］', '＾', '＿', '｀', '｛', '｜', '｝', '～', '｟', '｠', '｢', '｣', '､', '\\u3000', '、', '〃', '〈', '〉', '《', '》', '「', '」', '『', '』', '【', '】', '〔', '〕', '〖', '〗', '〘', '〙', '〚', '〛', '〜', '〝', '〞', '〟', '〰', '〾', '〿', '–', '—', '‘', '’', '‛', '“', '”', '„', '‟', '…', '‧', '﹏', '﹑', '﹔', '·', '！', '？', '｡', '。']\n",
    "    tokens = [token for token in tokens if token not in chinesePunctuations]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#從json檔讀取某主題的所有新聞的媒體、標題，內文，並把內文切成tokens\n",
    "def get_allRelatedNewsOnSpecificTopic(topicNum:int):\n",
    "    try:\n",
    "        df = pd.read_json('newsDatas.json')\n",
    "        allRelatedNewsOnSpecificTopic = []\n",
    "        for news in df[df['topicNum'] == topicNum].iloc[0]['allRelatedNews']:\n",
    "            tokens = chineseWordTokenizer(news['text'])\n",
    "            tempNews = {'docID':news['docID'],'media':news['media'],'title':news['title'],'tokens':tokens}\n",
    "            allRelatedNewsOnSpecificTopic.append(tempNews)\n",
    "        return allRelatedNewsOnSpecificTopic\n",
    "    except Exception as e:\n",
    "        print(\"讀取某主題的所有新聞時發生錯誤: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算某詞的tf\n",
    "def calculate_tf(word_list, document):\n",
    "    count = sum([1 for w in document if w in word_list])\n",
    "    return count\n",
    "\n",
    "#計算某主題中所有新聞文章的分數\n",
    "def calculate_tf_in_news_on_specific_topic(topicNum):\n",
    "    tf_dict = defaultdict(dict)\n",
    "    scores = []\n",
    "    document_list = []\n",
    "    allRelatedNews = get_allRelatedNewsOnSpecificTopic(topicNum)\n",
    "    for news in allRelatedNews:\n",
    "        document_list.append(news['tokens'])\n",
    "        \n",
    "    #計算每篇文章的分數\n",
    "    for i, document in enumerate(document_list):\n",
    "        tf_dict[i][\"title\"] = allRelatedNews[i][\"title\"]\n",
    "        tf_dict[i][\"docID\"] = allRelatedNews[i][\"docID\"]\n",
    "        tf_dict[i][\"media\"] = allRelatedNews[i][\"media\"]\n",
    "        good_score = calculate_tf(good_word, document)\n",
    "        bad_score = calculate_tf(bad_word, document)\n",
    "        score = good_score - bad_score\n",
    "        tf_dict[i][\"score\"] = score\n",
    "        scores.append(score)\n",
    "\n",
    "    inv_list = \"\"\n",
    "    highest_score_list = \"\"\n",
    "    lowest_score_list = \"\"\n",
    "    \n",
    "    #將分數不為0的文章加入inverted list\n",
    "    for i, score in enumerate(scores):\n",
    "        doc_title = tf_dict[i][\"title\"]\n",
    "        doc_name = tf_dict[i][\"docID\"]\n",
    "        doc_media = tf_dict[i][\"media\"]\n",
    "        if score != 0:\n",
    "            inv_list += f\"({doc_name},{score})\"\n",
    "            if score == max(scores):\n",
    "                highest_score_list += f\"新聞標題:{doc_title}, 媒體:{doc_media}, 文章代號:{doc_name}, 分數:{score}\\n\"\n",
    "            if score == min(scores):\n",
    "                lowest_score_list += f\"新聞標題:{doc_title}, 媒體:{doc_media}, 文章代號:{doc_name}, 分數:{score}\\n\"\n",
    "    print(f\"inv_list={inv_list}\")\n",
    "    print(f\"最高分 :\\n {highest_score_list}\")\n",
    "    print(f\"最低分 :\\n {lowest_score_list}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inv_list=(4-1,-1)(4-2,-5)(4-3,-2)(4-4,5)(4-5,-2)(4-6,6)(4-7,5)(4-8,-2)(4-9,15)(4-10,-5)(4-11,1)(4-12,-2)(4-13,-6)(4-14,4)(4-15,-1)(4-16,-7)(4-17,-7)\n",
      "最高分 :\n",
      " 新聞標題:韓家軍今造勢挺韓國瑜選總統 前韓市府局長曹桓榮將參加, 媒體:自由時報, 文章代號:4-9, 分數:15\n",
      "\n",
      "最低分 :\n",
      " 新聞標題:數千韓粉岡山造勢挺韓國瑜 籲國民黨列入總統民調, 媒體:經濟日報, 文章代號:4-16, 分數:-7\n",
      "新聞標題:數千韓粉岡山造勢挺韓國瑜 籲國民黨列入總統民調, 媒體:Yahoo奇摩新聞, 文章代號:4-17, 分數:-7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#測試 \n",
    "# 計算某主題的所有文章分數\n",
    "for i in range(1, 10):\n",
    "    calculate_tf_in_news_on_specific_topic(topicNum = i)\n",
    "#print(get_allRelatedNewsOnSpecificTopic(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
