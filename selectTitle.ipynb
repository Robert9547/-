{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 說明:\n",
    "# 本ipynb提供某篇新聞所有贊成與反對的留言"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import pandas as pd\n",
    "import import_ipynb\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from chinese_tokenizer import chineseWordTokenizer\n",
    "from emotionalDictionaryExtractor import get_positive_emotional_tokens\n",
    "from emotionalDictionaryExtractor import get_negative_emotional_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#全域變數\n",
    "good_word = get_positive_emotional_tokens() #所有正向情緒詞彙\n",
    "bad_word = get_negative_emotional_tokens()  #所有負向情緒詞彙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入新聞JSON檔的資料\n",
    "with open('newsDatas.json') as f:\n",
    "    all_news = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#爬取某個yahoo新聞的使用者留言\n",
    "def getMessage(newUrl: str):\n",
    "    try:\n",
    "        # 要爬取的Yahoo新聞網址url\n",
    "        #  = 'https://tw.news.yahoo.com/新聞台撤照案-中天勝訴-北高行撤銷ncc違法處分-201000270.html'\n",
    "        # url = 'https://tw.news.yahoo.com/朱立倫48小時2度會郭台銘-達成徵召侯友宜決定-130649010.html'\n",
    "        # 發送HTTP GET請求到該網址\n",
    "        response = requests.get(newUrl)\n",
    "\n",
    "        # 建立BeautifulSoup物件\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # spaceId\n",
    "        id_soup = soup.find_all(\n",
    "            'script', src=re.compile(\"https://s.yimg.com/aaq/c/\"))\n",
    "        idString = id_soup[0].find_next()\n",
    "        id = str(idString).split(\"'\")[1]\n",
    "        # print(\"spaceId:\"+id)\n",
    "\n",
    "        # context\n",
    "        context_soup = soup.find('meta', property=\"al:ios:url\")\n",
    "        context = context_soup['content'].split('/')[4]\n",
    "        # print(\"context:\"+context)\n",
    "\n",
    "        # messageSum\n",
    "\n",
    "        urlMessage = \"https://tw.news.yahoo.com/_td-news/api/resource/canvass.getPresence_ns;apiVersion=v1;context=\"+context + \\\n",
    "            \";lang=zh-Hant-TW;messageIds=;namespace=yahoo_content;oauthConsumerKey=frontpage.oauth.canvassKey;oauthConsumerSecret=frontpage.oauth.canvassSecret;region=TW?\"\n",
    "        payloadMessage = {}\n",
    "        headersMessage = {}\n",
    "        responseMessage = requests.request(\n",
    "            \"GET\", urlMessage, headers=headersMessage, data=payloadMessage)\n",
    "        messageSum = str(responseMessage.json()['messageCount'])\n",
    "        # print(messageSum)\n",
    "\n",
    "        # crawl\n",
    "        url = \"https://tw.news.yahoo.com/_td-news/api/resource/canvass.getMessageListForContext_ns;apiVersion=v1;context=\"+context+\";count=\"+\"100\" + \\\n",
    "            \";index=null;lang=zh-Hant-TW;namespace=yahoo_content;oauthConsumerKey=frontpage.oauth.canvassKey;oauthConsumerSecret=frontpage.oauth.canvassSecret;rankingProfile=;region=TW;sortBy=popular;spaceId=\"+id+\";\"\n",
    "\n",
    "        payload = {}\n",
    "        headers = {}\n",
    "\n",
    "        response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "\n",
    "        messages_origin = []\n",
    "        messages_token = []\n",
    "        \n",
    "        for i in response.json()['canvassMessages']:\n",
    "            message_origin = i['details']['userText']\n",
    "            message_token = chineseWordTokenizer(message_origin)\n",
    "            messages_origin.append(message_origin)\n",
    "            messages_token.append(message_token)\n",
    "        return messages_origin,messages_token\n",
    "    except Exception as e:\n",
    "        print(\"讀取某新聞的留言時發生錯誤: {}\".format(e))\n",
    "        return [],[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_o,m_t = getMessage(\"https://tw.news.yahoo.com/%E8%8A%AF%E8%8F%AF%E5%A4%A7%E6%88%B0-%E9%96%8B%E6%89%93-%E5%BE%90%E5%B7%A7%E8%8A%AF%E5%85%AC%E9%96%8B-%E8%A8%B1%E6%B7%91%E8%8F%AF%E7%9B%B8%E7%B0%BF-%E9%9B%99%E6%96%B9%E4%BA%92%E5%97%86%E8%96%AA%E6%B0%B4%E5%B0%8F%E5%81%B7-134702324.html\")\n",
    "# print(m_o[5])\n",
    "# print(m_t[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#某yahoo新聞內所有的媒體、標題，留言，並把留言切成tokens\n",
    "def get_all_comments_on_a_News(title:str):\n",
    "    try:\n",
    "        for topic in all_news:\n",
    "            for news in topic['allRelatedNews']:\n",
    "                if news['title'] == title:\n",
    "                    messages_origin,messages_token = getMessage(news['url']) #from kuan\n",
    "                    return {'messages_origin':messages_origin,'messages_token':messages_token}\n",
    "    except Exception as e:\n",
    "        print(\"讀取某新聞的留言時發生錯誤: {}\".format(e))\n",
    "        return dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = get_all_comments_on_a_News(\"「芯華大戰」開打！徐巧芯公開「許淑華相簿」 雙方互嗆薪水小偷\")\n",
    "# print(n['messages_origin'])\n",
    "# print(n['messages_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#計算某詞的tf\n",
    "def calculate_tf(word_list, comment):\n",
    "    count = sum([1 for w in comment if w in word_list])\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算某篇新聞的所有使用者留言的正負向分數\n",
    "def calculate_comment_score_in_a_news(title,messages_token):\n",
    "    try:\n",
    "        scores = []\n",
    "        if len(messages_token) > 0:\n",
    "            for message_token in messages_token:\n",
    "                one_comment_score = calculate_tf(good_word, message_token) - calculate_tf(bad_word, message_token)\n",
    "                scores.append(one_comment_score)\n",
    "            return scores \n",
    "    except Exception as e:\n",
    "        print(\"計算某篇新聞的所有留言分數時發生錯誤: {}\".format(e))\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_news_pos_neg_comments(title:str):\n",
    "    news = get_all_comments_on_a_News(title)\n",
    "    scores = calculate_comment_score_in_a_news(title,news['messages_token'])\n",
    "    positive_messages = [] # 所有贊成該新聞的留言\n",
    "    negative_messages = [] # 所有反對該新聞的留言\n",
    "    unknown_messages = [] # 所有立場不明確的留言\n",
    "    for ith,message in enumerate(news['messages_origin']) :\n",
    "        if scores[ith] > 0 :\n",
    "            positive_messages.append(message)\n",
    "        elif scores[ith] < 0 :\n",
    "            negative_messages.append(message)\n",
    "        else:\n",
    "            unknown_messages.append(message)\n",
    "    txt_file = open(\"某篇新聞的所有留言.txt\", \"a\")\n",
    "    txt_file.write(f\"標題： {title}\\n\")\n",
    "    txt_file.write(f\"========================\\n\")\n",
    "    txt_file.write(f\"贊成的留言：\\n\\n\")\n",
    "    for ith,message in enumerate(news['messages_origin']):\n",
    "        if message in positive_messages:\n",
    "            txt_file.write(f\"{message}\\n\")\n",
    "            txt_file.write(f\"-----------------------------\\n\")\n",
    "    txt_file.write(f\"========================\\n\")\n",
    "    txt_file.write(f\"反對的留言：\\n\\n\")\n",
    "    for ith,message in enumerate(news['messages_origin']):\n",
    "        if message in negative_messages:\n",
    "            txt_file.write(f\"{message}\\n\")\n",
    "            txt_file.write(f\"-----------------------------\\n\")\n",
    "    txt_file.write(f\"========================\\n\")\n",
    "    txt_file.write(f\"立場不明確的留言：\\n\\n\")\n",
    "    for ith,message in enumerate(news['messages_origin']):\n",
    "        if message in unknown_messages:\n",
    "            txt_file.write(f\"{message}\\n\")\n",
    "            txt_file.write(f\"-----------------------------\\n\")\n",
    "    txt_file.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#輸入標題\n",
    "print_news_pos_neg_comments(\"「芯華大戰」開打！徐巧芯公開「許淑華相簿」 雙方互嗆薪水小偷\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
