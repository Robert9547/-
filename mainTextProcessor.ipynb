{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#說明區\n",
    "#本ipynb處理爬到的新聞內文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from goose3 import Goose\n",
    "from goose3.text import StopWordsChinese\n",
    "from goose3.text import StopWordsKorean\n",
    "from goose3.text import StopWordsArabic\n",
    "import pandas as pd\n",
    "from fake_useragent import UserAgent\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goose抓內文\n",
    "def main_text_goose(url) -> str:\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\"}\n",
    "    content = \"\"\n",
    "    try:\n",
    "        url = requests.get(url).url # 取得原文連結(原先的url是被google news轉換過的)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code >= 400:# 爬蟲被擋\n",
    "            # 嘗試不被擋爬蟲\n",
    "            time.sleep(random.uniform(1, 3)) # 隨機暫停 1~3 秒，參考:https://ithelp.ithome.com.tw/articles/10224979\n",
    "            user_agent = UserAgent()# 隨機切換user_agent\n",
    "            response = requests.get(url=url,headers={ 'user-agent': user_agent.random })\n",
    "            if response.status_code >= 400:# 仍然被擋，放棄爬蟲\n",
    "                print(\"goose爬蟲被擋--Response Code:{}\".format(response.status_code))\n",
    "                print(\"文章網址: {}\".format(url))\n",
    "                return \"\"\n",
    "            \n",
    "        # 偵測文章語言\n",
    "        g = Goose() # 默認的method，若偵測不到文章語言，則會用這個method爬文章\n",
    "        language = response.headers.get(\"Content-Language\")\n",
    "        if language != None:\n",
    "            language = language.split('-')[0]\n",
    "            g = Goose({'use_meta_language': False, 'target_language':language})\n",
    "            # 中文、阿拉伯文、韓文等文章需要用到goose套件中的斷詞系統\n",
    "            if language == 'zh':# 中文\n",
    "                g = Goose({'stopwords_class': StopWordsChinese})\n",
    "            elif language == 'ar':# 阿拉伯文\n",
    "                g = Goose({'stopwords_class': StopWordsArabic})\n",
    "            elif language == 'ko':# 韓文\n",
    "                g = Goose({'stopwords_class':StopWordsKorean})\n",
    "                \n",
    "        # 爬取內文\n",
    "        article = g.extract(raw_html=response.text)\n",
    "        content = article.cleaned_text\n",
    "        \n",
    "        # 「文章有可能是中文，但先前沒偵測到文章語言」的額外處理\n",
    "        if language == None and len(article.title) != 0 and len(article.cleaned_text) == 0:\n",
    "            g = Goose({'stopwords_class': StopWordsChinese})\n",
    "            article = g.extract(raw_html=response.text)\n",
    "            content = article.cleaned_text \n",
    "            \n",
    "        # 檢查內文是否為空\n",
    "        if len(content) > 0:\n",
    "            return content   \n",
    "        else:   \n",
    "            print(\"goose抓不到內文\")    \n",
    "            print(\"文章網址: {}\".format(url))\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(\"can not get main text(goose)\\n\", e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將新聞的相關資料(標題、連結、內文等)寫入json檔\n",
    "def writeNewsDataToJson(newsMedia = \"\",newsTitle = \"\",newsUrl = \"\",newsTopicUrl = \"\"):\n",
    "    # 以下簡稱要加入json檔的新聞為「新聞a」\n",
    "    \n",
    "    # 爬取新聞a內文\n",
    "    text = \"\"\n",
    "    text = main_text_goose(newsUrl)\n",
    "    \n",
    "    # 爬到新聞a的內文才寫入json\n",
    "    if text != \"\": \n",
    "        df = pd.DataFrame() # df包含讀取以及寫入json檔的資料\n",
    "        fileName = 'newsDatas.json' # json檔名稱\n",
    "        newNews = {    # 新聞a的資訊\n",
    "            'media':newsMedia,  # 報導媒體\n",
    "            'title':newsTitle,  # 標題\n",
    "            'text':text,    # 內文\n",
    "            'url':newsUrl   # 連結\n",
    "        }\n",
    "        try: \n",
    "            df = pd.read_json(fileName)\n",
    "            if df.empty or len(df) == 0: #json檔內的所有新聞主題都被手動清空的情況\n",
    "                df = pd.DataFrame({'topicUrl': [], 'allRelatedNews': []})\n",
    "            try:\n",
    "                # 根據新聞a的主題連結，檢查json檔中是否存在新聞a\n",
    "                isFindNewsInItsTopic = 0 \n",
    "                for item in df[df['topicUrl'] == newsTopicUrl].iloc[0]['allRelatedNews']:\n",
    "                    if item['url'] == newsUrl:\n",
    "                          isFindNewsInItsTopic = 1\n",
    "                          break\n",
    "                      \n",
    "                # 若新聞a不在json檔內，則將新聞a加入json檔\n",
    "                if isFindNewsInItsTopic == 0: \n",
    "                    df[df['topicUrl'] == newsTopicUrl].iloc[0]['allRelatedNews'].append(newNews)\n",
    "                    df.to_json(fileName, orient='records', indent=4, force_ascii=False)  \n",
    "            except IndexError as e:\n",
    "                # 若新聞a的主題也不在json檔內，先將主題加入json檔\n",
    "                topicDataWithNewNews = {\n",
    "                    'topicUrl': [newsTopicUrl],\n",
    "                    'allRelatedNews':[[newNews]]\n",
    "                }\n",
    "                df = pd.concat([df, pd.DataFrame(topicDataWithNewNews)])\n",
    "                df.to_json(fileName, orient='records', indent=4, force_ascii=False)    \n",
    "            except Exception as e:\n",
    "                print(\"a發生非預期的錯誤：{}\".format(e))\n",
    "        except FileNotFoundError:\n",
    "            # json檔不存在或尚未創建\n",
    "            print('找不到json檔，將重新建立新的json檔')\n",
    "            df = pd.DataFrame({'topicUrl': [], 'allRelatedNews': []})\n",
    "            topicDataWithNewNews = {\n",
    "                'topicUrl': [newsTopicUrl],\n",
    "                'allRelatedNews':[[newNews]]\n",
    "            }\n",
    "            df = pd.concat([df, pd.DataFrame(topicDataWithNewNews)])\n",
    "            df.to_json(fileName, orient='records', indent=4, force_ascii=False)  \n",
    "        except Exception as e:\n",
    "            print(\"b發生非預期的錯誤：{}\".format(e))\n",
    "    return\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
