{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#說明區\n",
    "#本ipynb處理爬到的新聞內文\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from goose3 import Goose\n",
    "from goose3.text import StopWordsChinese\n",
    "from goose3.text import StopWordsKorean\n",
    "from goose3.text import StopWordsArabic\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goose抓內文\n",
    "def main_text_goose(url) -> str:\n",
    "    1\n",
    "    headers = {\"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36\"}\n",
    "    content = \"\"\n",
    "    try:\n",
    "        url = requests.get(url).url # 取得原文連結(原先的url是被google news轉換過的)\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code<400:# 爬蟲沒被擋 \n",
    "            # 偵測文章語言\n",
    "            g = Goose() # 默認的method，若偵測不到文章語言，則會用這個method爬文章\n",
    "            language = response.headers.get(\"Content-Language\")\n",
    "            if language != None:\n",
    "                language = language.split('-')[0]\n",
    "                g = Goose({'use_meta_language': False, 'target_language':language})\n",
    "                # 中文、阿拉伯文、韓文等文章需要用到goose套件中的斷詞系統\n",
    "                if language == 'zh':# 中文\n",
    "                    g = Goose({'stopwords_class': StopWordsChinese})\n",
    "                elif language == 'ar':# 阿拉伯文\n",
    "                    g = Goose({'stopwords_class': StopWordsArabic})\n",
    "                elif language == 'ko':# 韓文\n",
    "                    g = Goose({'stopwords_class':StopWordsKorean})\n",
    "                    \n",
    "            # 爬取內文\n",
    "            article = g.extract(raw_html=response.text)\n",
    "            content = article.cleaned_text\n",
    "            \n",
    "            # 「文章有可能是中文，但先前沒偵測到文章語言」的額外處理\n",
    "            if language == None and len(article.title) != 0 and len(article.cleaned_text) == 0:\n",
    "                g = Goose({'stopwords_class': StopWordsChinese})\n",
    "                article = g.extract(raw_html=response.text)\n",
    "                content = article.cleaned_text \n",
    "            '''\n",
    "            print(\"=====goose content=====\")\n",
    "            print(content)\n",
    "            print(\"=================\\n\")'''\n",
    "            # 檢查內文是否為空\n",
    "            if len(content) > 0:\n",
    "                return content   \n",
    "            else:   \n",
    "                print(\"goose抓不到內文\")    \n",
    "                print(\"文章網址: {}\".format(url))\n",
    "                return \"\"\n",
    "        else:\n",
    "            print(\"goose爬蟲被擋--Response Code:{}\".format(response.status_code))\n",
    "            print(\"文章網址: {}\".format(url))\n",
    "            return \"\"\n",
    "    except Exception as e:\n",
    "        print(\"can not get main text(goose)\\n\", e)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將新聞的相關資料(標題、連結、內文等)寫入json檔\n",
    "def writeNewsDataToJson(newsMedia = \"\",newsTitle = \"\",newsUrl = \"\"):\n",
    "    # 爬取新聞內文\n",
    "    text = \"\"\n",
    "    text = main_text_goose(newsUrl)\n",
    "    \n",
    "    # 寫入json (url這一項要留著，用來判斷有沒有抓到重複的新聞)\n",
    "    fileName = 'newsDatas.json'# json檔名稱\n",
    "    newsData = {    # 要加入json檔的新聞\n",
    "        'media':[newsMedia],  # 報導媒體\n",
    "        'title':[newsTitle],  # 標題\n",
    "        'text':[text],    # 內文\n",
    "        'url':[newsUrl]   # 連結\n",
    "    }\n",
    "    df = pd.DataFrame()\n",
    "    try:    \n",
    "        df = pd.read_json(fileName)\n",
    "    except FileNotFoundError:\n",
    "        print('找不到json檔，將重新建立新的json檔')\n",
    "        df = pd.DataFrame({'media': [], 'title': [],'text':[],'url':[]})\n",
    "    except Exception:\n",
    "        df = pd.DataFrame({'media': [], 'title': [],'text':[],'url':[]})\n",
    "    if df.empty or (newsUrl not in df['url'].values):# 若json檔內沒有此篇新聞(以新聞連結判斷)，則加入此新聞\n",
    "        df = pd.concat([df, pd.DataFrame(newsData)])\n",
    "        df.to_json(fileName, orient='records', indent=4, force_ascii=False) \n",
    "    return\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
